{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+U0RP0DKFtlkJ6y+Eaa5l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/firmanlaia12/Data_Firman/blob/main/projec_1_data_mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jP6H1pc7KN9j"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "zW4XNkk3NYEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json #fungsi untuk memberikan izin akses file"
      ],
      "metadata": {
        "id": "gJZiqST9OR0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d akshaydattatraykhare/diabetes-dataset"
      ],
      "metadata": {
        "id": "Z9u5YQDkQGH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('diabetes-dataset.zip', 'r')as zip_ref:\n",
        "  zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "Ibn2kg4WRz81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection importtrain_test_split\n",
        "from sklearn.ensemble import RandomForestCIassifier\n",
        "from sklearn.neishbors import KNeighbcrsCIassifier\n",
        "from sklearn.neural_network import MLPCIassifier\n",
        "from sklearn.svm import SVC\n",
        "\n"
      ],
      "metadata": {
        "id": "kBt24N8OTLN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = Pd.rady_csv_('/content/diabetes.csv')\n",
        "display(df.head(2)) # display fisrt record of data\n",
        "display(df.tail(2)) # display Iast 4 rocord of data\n",
        "display(df. sampIe(4)) # display ramdomly any number of record of data"
      ],
      "metadata": {
        "id": "ToR7abHHehCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of rows and colums\n",
        "df.shape\n",
        "df.dtypes\n",
        "df.info()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FtgGZyvZgm9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "Check Null Value"
      ],
      "metadata": {
        "id": "N7-C27UjkLNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape before drop duplicate\n",
        "df.shape\n",
        "\n",
        "    (768, 9)\n",
        "\n",
        "df=df.drop_duplicates()\n",
        "\n",
        "# check the shape after drop the duplicate\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Iq8gYAcpkmul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check of null values,\n",
        "# check the missing value in any column,\n",
        "# display number of null value in every column in dataset.\n",
        "df.isnull().sum()\n",
        "\n",
        "\n",
        "df. columns\n"
      ],
      "metadata": {
        "id": "Rw3DxEbaleP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('No of zero value in Glucose', df[df['Glucose']==0].shape[0])\n",
        "\n",
        "print ('No of zero value in BloodPressure', df[df['BloodPressure']==0].shape[0])\n",
        "\n",
        "print ('No of zero value in SkinThickness', df[df['SkinThickness']==0].shape[0])\n",
        "\n",
        "      No of zero value in SkinThickness 227\n",
        "\n",
        "print ('No of zero value in Insulin', df[df['Insulin']==0].shape[0])\n",
        "\n",
        "print ('No of zero value in BMI', df[df['BMI']==0].shape[0])"
      ],
      "metadata": {
        "id": "cdIjusUFl3ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Glucose']=df['Glucose'].replace(0,df['Glucose'].mean())\n",
        "print('no of zero value in Glucose',df[df['Glucose']==0].shape[0])\n",
        "\n",
        "df['BloodPressure']=df[BloodPressure].replace(0,df['BloodPressure'].mean())\n",
        "df['SkinThickness']=df[SkinThickness].replace(0,df['SkinThickness'].mean())\n",
        "df['Insulin']=df['Insulin'].replace(0,df['Insulin'].mean())\n",
        "df['BMI']=df['BMI'].replace(0df['BMI'].mean())\n",
        "\n",
        "df.describe()\n",
        "\n",
        "# utcome coun plot\n",
        "f,ax=plt.subplots(1,2,figsize=(10,5))\n",
        "df,['Outcome'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
        "ax[0].set_title('outcome')\n",
        "ax[0].set_ylabel('')\n",
        "sns.countplot(x='outcom',data=df,ax=aax[1])\n",
        "ax[1].set_title('outcome')\n",
        "N,P = df['outcome'].value_counts()\n",
        "print('Negative (0):',N)\n",
        "print('Positive (1):',N)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ro_KrhJNp2FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(bins=10,figsize=(10,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KeGyY1Mzx-7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "scatter_matrix(df, figsize = (20,20));"
      ],
      "metadata": {
        "id": "Yy-Hz2bTycHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "corrmat = df.corr()\n",
        "top_corr_feature = corrmat.index\n",
        "plt.figure(figsize=(10,10))\n",
        "g=sns.heatmap(df[top_corr_feature].corr(),annot=True,cmap=\"viridis\")"
      ],
      "metadata": {
        "id": "W4ReC5ILzMWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targe_name = 'outcome'\n",
        "y = df[target_name]\n",
        "x = df.drop(terget_name, axis=1)\n",
        "\n",
        "x.head()\n",
        "\n",
        "y.head()"
      ],
      "metadata": {
        "id": "Q7JG3G7l0jXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaIer\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x)\n",
        "SSX = scaler.transform(x)\n"
      ],
      "metadata": {
        "id": "kXiA5t8b-TZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model selection import tranin_test_split\n",
        " x_train, x_test, y_train, y_test = train_test_split(ssx, y, test_size=0.2, random_state=7)\n",
        "\n",
        "\n",
        " x_train.shape, y_train.shape\n",
        "\n",
        " x_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "NpImIAkW-14X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "sv=SVC()\n",
        "sv.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "njK2cuG5BBAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sv_pred=sv.predict(x_test)\n",
        "\n",
        "sv_pred.shape\n",
        "\n",
        "    (154,)"
      ],
      "metadata": {
        "id": "r69Fxsa5BluN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train score & test score SVN\n",
        "from sklearn.metrics import accuracy_score\n",
        "print (\"Train Accuracy of SVM\", sv.score(x-train, y-train)*100)\n",
        "print (\"Accuracy (test) score of SVM\", sv.score(x_test, y_test)*100)\n",
        "print (\"Accuracy (test) score of SVM\", accuracy_score (y_test, sv_test, sv_pred)*100)"
      ],
      "metadata": {
        "id": "aGQVyvn1Cm6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Curve & ROC AUC ROC curve is one the import evaluating metrics that should be used to check performance of clasification model. it is also called relative operating characteristic curve, because is a comparison of two main characteristics (TPR & FBR). It is plotted between sensitivity (aka recall aka True Positive Rate) and False Positive Rate (FBR = 1 -spesificisty). ROC(Receciver Operating Characteristic) Curve tells about how good the model can distinguish between two thing . AUC(Area Under Cruve) helps us to choose the best model amongst the model for which we have plotted the ROC curves\n",
        "\n",
        "Confusion Matrix of \"SVM\"\n"
      ],
      "metadata": {
        "id": "R-O7dRKlD5T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion matrix\n",
        "# Confusion matrix of Logistic Regression\n",
        "cm=confusion_matrix(y_test,sv-pred)\n",
        "cm\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, sv_pred),annot=True,fmt='d')\n",
        "\n",
        "print ('Classifiacation Report of svm: \\n', classification-report,(y_test,sv_pred,digits=4 ))\n",
        "\n",
        "TN = cm[0,0]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "TP = cm[1,1]\n",
        "\n",
        "TN, FP, FN, TP\n",
        "\n",
        "# Making the Confusion Matrix of SVN\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm = confusion_matrix(y_test, sv_pred)\n",
        "cm\n",
        "\n",
        "# Making the Confusion Matrix of SVN\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "cm=confusion_matrix(y_test, sv_pred)\n",
        "\n",
        "print('TN - True Negative {}'. format(cm[0,0]))\n",
        "print('FP - False Positive {}'. format(cm[0,1]))\n",
        "print('FN - False Negative {}'. format(cm[1,0]))\n",
        "print('TP - True Positive {}'. format(cm[1,1]))\n",
        "print('Accuracy Rate of SVM:{}'.format(np.divide(np.sum([cm[0,0],cm[1,1]]),np.sum(cm))*100))\n",
        "print ('Misclassification Rate of SVM :{}'.format(np.divide(np.sum([cm[0,1],cm[1,0]]),np.sum(cm))*100))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, sv_pred),cmap='Blues', annot=True, fmt=\"d\")\n",
        "\n",
        "\n",
        "Classification Report of SVM\n",
        "\n",
        "print('Classsification Report of SVM:\\n', classificaton_report(y_test,sv_pred,digits=4))\n",
        "\n",
        "TN = cm[0,0]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]\n",
        "TP = cm[1,1]\n",
        "\n",
        "TN, FP, FN, TP\n",
        "\n",
        "# PRECISION (PFW-Positive Prediction Value)\n",
        "# Precision = TP/(TP+FP), Where TP = True Positive, FP = False Positive\n",
        "TP,FN\n",
        "\n",
        "Precision=TP/(TP+FP)\n",
        "precision\n",
        "\n",
        "Precision_score = TP/float(TP+FP)*100\n",
        "print('precision score : {0:0,4f}'.format(precision_score))\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "print(\"Precision Score is:\", precision_score(y_test,sv_pred)*100)\n",
        "print (\"Mirco Average precision Score is:\", precision_score(y_test, sv_pred, average='micro')*100)\n",
        "print (\"Marco Average precision Score is:\", precision_score(y_test, sv_pred, average='macro' )*100)\n",
        "print (\"Weighted Average precision Score is:\", precision_score(y_test sv_pred, average='weighted')*100)\n",
        "print (\"Precision Score on non weighted score is:\", precision_score(y_test sv_pred, average=None)*100)\n",
        "\n",
        "recall_score = TP/float(TP + FN)*100\n",
        "print ('recall_score',recall_score)\n",
        "\n",
        "TP, FN\n",
        "\n",
        "recall_score = TP/FN\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "print('Recall or Sensitivity_score :', recall_score(y_test,sv_pred)*100)\n",
        "\n",
        "print (\"Micro Average Recall Score is :\", recall_score(y_test, sv_pred,average='micro')*100)\n",
        "print (\"Macro Average Recall Score is :\", recall_score(y_test, sv_pred,average='macro')*100)\n",
        "print (\"Weighted Average Recall Score is :\" recall_score(y_test, sv_pred,average='weighted')*100)\n",
        "print (\"Recall Score on Non weighted score is:\" recall_score(y_test, sv_pred,average=None)*100)\n",
        "\n",
        "print ('Classification Report of Neural Network: \\',classification_report(y_test, sv_pred,digits=4))\n",
        "\n",
        "#FALSE POSITIVE RATE ( FPR )\n",
        "FPR = FP/float(FP+TN)*100\n",
        "print('False Positive Rate :{ø:e.4f}' .format(FPR))\n",
        "\n",
        "FP,TN\n",
        "\n",
        "14/(14+83)\n",
        "\n",
        "#SPECIFICITY\n",
        "specificity = TN / (TN + FP )*100\n",
        "print('specificity :{0:0.4f}' .format(specificity))\n",
        "\n",
        "Fl Score\n",
        "\n",
        "from sklearn.metrics import f1 score\n",
        "print ('fl_score of macro:',f1_score(y_test, sv_pred)*100)\n",
        "\n",
        "print (\"Micro Average fl Score is :\", f1_score(y_test,sv_pred,average='micro')*100)\n",
        "print (\"Macro Average fl Score is :\", f1_score(y_test,sv_pred,average='macro')*100)\n",
        "print (\"Weighted Average fl Score is:\", fl_score(y_test,sv_pred,average='weighted')*100)\n",
        "print (\"fl Score on Non weighted score is:\", fl_score(y_test,sv_pred,average=None)*100)\n",
        "\n",
        "ROC AUC of SVM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Area Under Curve\n",
        "auc = roc_auc_score(y_test, sv_pred)\n",
        "print(ROC AUC SCORE of SVW is\",auc)\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "auc = round(roc_auc_score(y_test,sv_pred)*100,2)\n",
        "print(\"ROC AUC SCORE of SVM is\",auc)\n",
        "\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, sv_pred)\n",
        "plt.plot(fpr, tpr, color='orange', label='ROC')\n",
        "plt.plot([0,1], [0,1], color='darkblue', linestyle='--',label='ROC curve(area = 0%.2f)'% auc)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.yIabeI('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) of SVM' )\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IJt2VuG8EHbz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}